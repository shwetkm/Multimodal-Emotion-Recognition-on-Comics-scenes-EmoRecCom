{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5tUoHe9FRhs"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dr7BCHS-nIRW",
    "outputId": "97b5954d-b5ed-4e7d-d4d6-467338460082",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "from transformers import BertTokenizer, XLNetTokenizer, RobertaTokenizer, BertForSequenceClassification, XLNetForSequenceClassification, RobertaForSequenceClassification, AdamW\n",
    "from tqdm import tqdm, trange\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zB5Dij6JuItX"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhjnJEwKnISB",
    "outputId": "c2cbeb3d-3c57-4257-d478-ef909dd33b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uorMX_zrnISM",
    "outputId": "8f87795c-c87b-4b99-b996-d9276714feed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLcetMjZFjSH"
   },
   "source": [
    "## Load and Preprocess Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6V87OiJjfHO",
    "outputId": "a94ccf8c-e2a6-4060-b038-bba02672650b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shwetkm/EmoRegCom/nbs\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4365, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/train_np_img_norm','rb') as f: X_img_train = pickle.load(f)\n",
    "X_img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 4365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/test_np_img_norm', 'rb') as f: X_img_test = pickle.load(f)\n",
    "X_img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/val_np_img_norm', 'rb') as f: X_img_val = pickle.load(f)\n",
    "X_img_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train = X_img_train[:sample_size]\n",
    "X_img_val = X_img_val[:sample_size]\n",
    "X_img_test = X_img_test[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 3, 224, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_img_val = np.reshape(X_img_val, (X_img_val.shape[0], 3, 224, 224))\n",
    "X_img_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_test = np.reshape(X_img_test, (X_img_test.shape[0], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train = np.reshape(X_img_train, (X_img_train.shape[0], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "0ecREc7GnISW",
    "outputId": "791a61a7-a4c1-488f-dad7-8635f1fd19da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/public_train/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AhWrzX7nITB",
    "outputId": "972b4db0-86d5-4553-a8c1-51415a409566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ocr_texts:  False\n",
      "Null values:  False\n"
     ]
    }
   ],
   "source": [
    "print('Unique ocr_texts: ', df.text_clean.nunique() == df.shape[0])\n",
    "print('Null values: ', df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkKpz_9eJRt7",
    "outputId": "4745fb8b-c3ee-4218-f7ef-ae9343517f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average sentence length:  25.596334478808707\n",
      "stdev sentence length:  24.795639258733278\n"
     ]
    }
   ],
   "source": [
    "print('average sentence length: ', df.text_clean.str.split().str.len().mean())\n",
    "print('stdev sentence length: ', df.text_clean.str.split().str.len().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVI59S9VaAfB",
    "outputId": "518cce78-c9c5-47d0-a9ea-ef422c6a7628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label columns:  ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral', 'Others']\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "label_cols = list(cols[2:10])\n",
    "num_labels = len(label_cols)\n",
    "print('Label columns: ', label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "0DF3ddjej5vd",
    "outputId": "13270850-dae3-466b-d371-6d533a8c745f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1308_48_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>['wait a minute i am not going to hurt you   !']</td>\n",
       "      <td>['Angry', 'Happy']</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>3766_29_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>['he thought they need a new careman , looks l...</td>\n",
       "      <td>['Disgust', 'Happy', 'Neutral']</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2112_17_7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action , his bouyancy a...</td>\n",
       "      <td>['Angry', 'Disgust']</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>3458_16_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>['is it there   .is not mate?', 'yeah t is in ...</td>\n",
       "      <td>['Neutral']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>2338_19_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>['listen and pass your way   . bzzzz21   .', '...</td>\n",
       "      <td>['Fear', 'Surprise', 'Neutral']</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   575.0  1308_48_2      1        0     0      1    0         0        0   \n",
       "1  5395.0  3766_29_2      0        1     0      1    0         0        1   \n",
       "2  2004.0  2112_17_7      1        1     0      0    0         0        0   \n",
       "3  4863.0  3458_16_7      0        0     0      0    0         0        1   \n",
       "4  5146.0  2338_19_3      0        0     1      0    0         1        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0       ['wait a minute im not going to hurt you !']   \n",
       "1       0  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2       0  ['the comet leaps into action his bouyancy all...   \n",
       "3       0  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4       0  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                           narration  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                                text  \\\n",
       "0       ['wait a minute im not going to hurt you !']   \n",
       "1  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0   ['wait a minute i am not going to hurt you   !']   \n",
       "1  ['he thought they need a new careman , looks l...   \n",
       "2  ['the comet leaps into action , his bouyancy a...   \n",
       "3  ['is it there   .is not mate?', 'yeah t is in ...   \n",
       "4  ['listen and pass your way   . bzzzz21   .', '...   \n",
       "\n",
       "                      emotion_list            one_hot_labels  \n",
       "0               ['Angry', 'Happy']  [1, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1  ['Disgust', 'Happy', 'Neutral']  [0, 1, 0, 1, 0, 0, 1, 0]  \n",
       "2             ['Angry', 'Disgust']  [1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3                      ['Neutral']  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4  ['Fear', 'Surprise', 'Neutral']  [0, 0, 1, 0, 0, 1, 1, 0]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['one_hot_labels'] = list(df[label_cols].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MlhHifh5bW7e"
   },
   "outputs": [],
   "source": [
    "train_labels = list(df.one_hot_labels.values)\n",
    "ocr_texts = list(df.text_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4365.000000\n",
       "mean       25.596334\n",
       "std        24.795639\n",
       "min         1.000000\n",
       "25%        12.000000\n",
       "50%        21.000000\n",
       "75%        33.000000\n",
       "max       616.000000\n",
       "Name: text_clean, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_clean.apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNsEu-vUur-4",
    "outputId": "baf4e3f3-6015-4419-dce0-f4125bbdcbad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "max_length = 35\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n",
    "encodings = tokenizer.batch_encode_plus(ocr_texts,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l6CCLSjfur-9"
   },
   "outputs": [],
   "source": [
    "train_inputs = encodings['input_ids'] # tokenized and encoded sentences\n",
    "train_token_types = encodings['token_type_ids'] # token type ids\n",
    "train_masks = encodings['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9PxAt48HRRj"
   },
   "source": [
    "Be sure to handle all classes during validation using \"stratify\" during train/validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WPFaq4ufnIT2"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_types = torch.tensor(train_token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "G5Q7hC4GFOLJ",
    "outputId": "5cb49a39-b967-43f8-9cea-c97d027e194e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n",
      "Same columns between train and validation:  True\n"
     ]
    }
   ],
   "source": [
    "validation_df = pd.read_csv('../data/public_train/val_data.csv')\n",
    "validation_label_cols = list(validation_df.columns[2:10])\n",
    "print('Null values: ', validation_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "print('Same columns between train and validation: ', label_cols == validation_label_cols) #columns should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "77rjCrMGpYxz",
    "outputId": "d9682639-991e-472c-d07f-33336b85f589"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1179_7_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['plummets down', 'he vaul7 front']</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['ops   ! cheap twine or must have gained weig...</td>\n",
       "      <td>['Sad', 'Surprise']</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>2258_29_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>['just a minute , you   .   .   .   .']</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>3832_23_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>['they think they bungled and are going to rep...</td>\n",
       "      <td>['Angry', 'Disgust', 'Sad', 'Neutral']</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1377_39_7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>['wow   .']</td>\n",
       "      <td>['Angry', 'Surprise', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>777_20_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>['look nightmare   ! he is gone through the we...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   340.0   1179_7_2      0        0     0      0    1         1        0   \n",
       "1  3831.0  2258_29_2      1        1     1      1    0         0        1   \n",
       "2  2465.0  3832_23_3      1        1     0      0    1         0        1   \n",
       "3   672.0  1377_39_7      1        0     0      0    0         1        1   \n",
       "4  5145.0   777_20_0      1        0     0      0    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1       0                       [' just a minute , you ...']   \n",
       "2       0  [\"they think they bungled and are going to rep...   \n",
       "3       0                                          ['owuch']   \n",
       "4       0  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                             narration  \\\n",
       "0  ['plummets down', 'he vaul7 front']   \n",
       "1                                   []   \n",
       "2                                   []   \n",
       "3                                   []   \n",
       "4                                   []   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1                       [' just a minute , you ...']   \n",
       "2  [\"they think they bungled and are going to rep...   \n",
       "3                                          ['owuch']   \n",
       "4  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['ops   ! cheap twine or must have gained weig...   \n",
       "1            ['just a minute , you   .   .   .   .']   \n",
       "2  ['they think they bungled and are going to rep...   \n",
       "3                                        ['wow   .']   \n",
       "4  ['look nightmare   ! he is gone through the we...   \n",
       "\n",
       "                                       emotion_list            one_hot_labels  \n",
       "0                               ['Sad', 'Surprise']  [0, 0, 0, 0, 1, 1, 0, 0]  \n",
       "1  ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']  [1, 1, 1, 1, 0, 0, 1, 0]  \n",
       "2            ['Angry', 'Disgust', 'Sad', 'Neutral']  [1, 1, 0, 0, 1, 0, 1, 0]  \n",
       "3                  ['Angry', 'Surprise', 'Neutral']  [1, 0, 0, 0, 0, 1, 1, 0]  \n",
       "4                              ['Angry', 'Neutral']  [1, 0, 0, 0, 0, 0, 1, 0]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df['one_hot_labels'] = list(validation_df[validation_label_cols].values)\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1a41OmU2i7qp"
   },
   "outputs": [],
   "source": [
    "validation_labels = list(validation_df.one_hot_labels.values)\n",
    "validation_ocr_texts = list(validation_df.text_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amySMO8EQzf2",
    "outputId": "05a48e2e-8b6d-4000-a5e7-cbc9c23b7b17"
   },
   "outputs": [],
   "source": [
    "# Encoding input data\n",
    "validation_encodings = tokenizer.batch_encode_plus(validation_ocr_texts,max_length=max_length,pad_to_max_length=True)\n",
    "validation_input_ids = validation_encodings['input_ids']\n",
    "validation_token_type_ids = validation_encodings['token_type_ids']\n",
    "validation_attention_masks = validation_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hqOfi9fkRaRN"
   },
   "outputs": [],
   "source": [
    "# Make tensors out of data\n",
    "validation_inputs = torch.tensor(validation_input_ids)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_attention_masks)\n",
    "validation_token_types = torch.tensor(validation_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "G5Q7hC4GFOLJ",
    "outputId": "5cb49a39-b967-43f8-9cea-c97d027e194e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n",
      "Same columns between train and test:  True\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/public_train/test_data.csv')\n",
    "test_label_cols = list(test_df.columns[2:10])\n",
    "print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "print('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "77rjCrMGpYxz",
    "outputId": "d9682639-991e-472c-d07f-33336b85f589"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4184.0</td>\n",
       "      <td>3812_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>[\"tha day prog ahranean the recovery ou thats ...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Neutral']</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1088_28_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>['he is not telling all he knows , do you thin...</td>\n",
       "      <td>['Angry', 'Fear', 'Neutral']</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>479_14_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>['you big stupid why do not you watch where yo...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>859_24_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>['fight it out with him it is the gallows if h...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4762.0</td>\n",
       "      <td>2260_47_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['this way to the roof']</td>\n",
       "      <td>['the fleeing boxer and photographer']</td>\n",
       "      <td>['this way to the roof', 'the fleeing boxer an...</td>\n",
       "      <td>['this way to the roof   .', 'the fleeing boxe...</td>\n",
       "      <td>['Fear', 'Happy', 'Neutral']</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0  4184.0   3812_3_3      1        1     1      0    0         0        1   \n",
       "1   132.0  1088_28_3      1        0     1      0    0         0        1   \n",
       "2  3543.0   479_14_0      1        0     0      0    0         0        1   \n",
       "3  4692.0   859_24_1      1        1     1      0    0         1        1   \n",
       "4  4762.0  2260_47_8      0        0     1      1    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['or this what kind of reputation are these pi...   \n",
       "1       0  [\"he ' s not telling all he knows do you think...   \n",
       "2       0  [\"you big stupid why don ' t you watch where y...   \n",
       "3       0  [\"fight it out with him it ' s the gallows if ...   \n",
       "4       0                           ['this way to the roof']   \n",
       "\n",
       "                                           narration  \\\n",
       "0  [\"tha day prog ahranean the recovery ou thats ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4             ['the fleeing boxer and photographer']   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  [\"he ' s not telling all he knows do you think...   \n",
       "2  [\"you big stupid why don ' t you watch where y...   \n",
       "3  [\"fight it out with him it ' s the gallows if ...   \n",
       "4  ['this way to the roof', 'the fleeing boxer an...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  ['he is not telling all he knows , do you thin...   \n",
       "2  ['you big stupid why do not you watch where yo...   \n",
       "3  ['fight it out with him it is the gallows if h...   \n",
       "4  ['this way to the roof   .', 'the fleeing boxe...   \n",
       "\n",
       "                                        emotion_list            one_hot_labels  \n",
       "0            ['Angry', 'Disgust', 'Fear', 'Neutral']  [1, 1, 1, 0, 0, 0, 1, 0]  \n",
       "1                       ['Angry', 'Fear', 'Neutral']  [1, 0, 1, 0, 0, 0, 1, 0]  \n",
       "2                               ['Angry', 'Neutral']  [1, 0, 0, 0, 0, 0, 1, 0]  \n",
       "3  ['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...  [1, 1, 1, 0, 0, 1, 1, 0]  \n",
       "4                       ['Fear', 'Happy', 'Neutral']  [0, 0, 1, 1, 0, 0, 1, 0]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1a41OmU2i7qp"
   },
   "outputs": [],
   "source": [
    "# Gathering input data\n",
    "test_labels = list(test_df.one_hot_labels.values)\n",
    "test_ocr_texts = list(test_df.text_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amySMO8EQzf2",
    "outputId": "05a48e2e-8b6d-4000-a5e7-cbc9c23b7b17"
   },
   "outputs": [],
   "source": [
    "# Encoding input data\n",
    "test_encodings = tokenizer.batch_encode_plus(test_ocr_texts,max_length=max_length,pad_to_max_length=True)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_token_type_ids = test_encodings['token_type_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hqOfi9fkRaRN"
   },
   "outputs": [],
   "source": [
    "# Make tensors out of data\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_token_types = torch.tensor(test_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 273\n",
      "31 31\n",
      "76 76\n"
     ]
    }
   ],
   "source": [
    "text_train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
    "img_train_data = TensorDataset(torch.from_numpy(X_img_train), train_labels)\n",
    "\n",
    "text_val_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
    "img_val_data = TensorDataset(torch.from_numpy(X_img_val), validation_labels)\n",
    "\n",
    "text_test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
    "img_test_data = TensorDataset(torch.from_numpy(X_img_test), test_labels)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "text_train_loader = DataLoader(text_train_data, batch_size=batch_size)\n",
    "img_train_loader = DataLoader(img_train_data, batch_size=batch_size)\n",
    "\n",
    "text_val_loader = DataLoader(text_val_data, batch_size=batch_size)\n",
    "img_val_loader = DataLoader(img_val_data, batch_size=batch_size)\n",
    "\n",
    "text_test_loader = DataLoader(text_test_data, batch_size=batch_size)\n",
    "img_test_loader = DataLoader(img_test_data, batch_size=batch_size)\n",
    "\n",
    "print(len(text_train_loader), len(img_train_loader))\n",
    "print(len(text_val_loader), len(img_val_loader))\n",
    "print(len(text_test_loader), len(img_test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncGteBuSFuZM"
   },
   "source": [
    "## Load Model & SetÂ Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ujk4k16DnIT6",
    "outputId": "f2933ef1-9f4f-4942-f08e-43c7573244ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model, the pretrained model will include a single linear classification layer on top for classification. \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGE4gv9qfhRG"
   },
   "source": [
    "Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GsV8zwWYnIT9"
   },
   "outputs": [],
   "source": [
    "# setting custom optimization parameters.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "aOomZIEIoHOL"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
    "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRQQZ8zIFzLW"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDLZmEC_oKo3",
    "outputId": "99ab5322-abdb-4d21-d256-16e9cfc41256"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5749105777277614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|ââ        | 1/5 [02:49<11:19, 169.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5705188455120209\n",
      "F1 Validation Accuracy:  25.65019451588873\n",
      "Flat Validation Accuracy:  7.20164609053498\n",
      "ROC AUC Score:  53.793826353090864\n",
      "Train loss: 0.5439539429468986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|ââââ      | 2/5 [05:43<08:36, 172.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.565084324729058\n",
      "F1 Validation Accuracy:  32.53643399117978\n",
      "Flat Validation Accuracy:  7.20164609053498\n",
      "ROC AUC Score:  55.682933678723415\n",
      "Train loss: 0.5034820013867193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|ââââââ    | 3/5 [08:32<05:41, 170.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5782314712001432\n",
      "F1 Validation Accuracy:  33.74888845903668\n",
      "Flat Validation Accuracy:  6.995884773662551\n",
      "ROC AUC Score:  55.963382106910586\n",
      "Train loss: 0.45082390788710597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|ââââââââ  | 4/5 [11:23<02:50, 170.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6166491220074315\n",
      "F1 Validation Accuracy:  34.70450395297884\n",
      "Flat Validation Accuracy:  6.790123456790123\n",
      "ROC AUC Score:  56.09149635463038\n",
      "Train loss: 0.39367308077358065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|ââââââââââ| 5/5 [14:21<00:00, 172.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6620262188296164\n",
      "F1 Validation Accuracy:  37.060902068724936\n",
      "Flat Validation Accuracy:  3.909465020576132\n",
      "ROC AUC Score:  55.897397638649025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "val_loss_set = []\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "\n",
    "  # Tracking variables\n",
    "  tr_loss = 0 #running loss\n",
    "  val_loss = 0 #running loss\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  nb_val_steps = 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(text_train_loader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass for multilabel classification\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    loss_func = BCEWithLogitsLoss() \n",
    "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "    # loss_func = BCELoss() \n",
    "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "    train_loss_set.append(loss.item())    \n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Variables to gather full output\n",
    "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "  # Predict\n",
    "  for i, batch in enumerate(text_val_loader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "      b_logit_pred = outs[0]\n",
    "      v_loss = loss_func(b_logit_pred.view(-1,num_labels),b_labels.type_as(b_logit_pred).view(-1,num_labels)) #convert labels to float for calculation\n",
    "      val_loss_set.append(v_loss.item())  \n",
    "      val_loss += v_loss.item()\n",
    "      pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "      pred_label = pred_label.to('cpu').numpy()\n",
    "      b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "    nb_val_steps += 1\n",
    "\n",
    "  print(\"Val loss: {}\".format(val_loss/nb_val_steps))\n",
    "  # Flatten outputs\n",
    "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "  true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "  # Calculate Accuracy\n",
    "  threshold = 0.50\n",
    "  pred_bools = [pl>threshold for pl in pred_labels]\n",
    "  true_bools = [tl==1 for tl in true_labels]\n",
    "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='macro')*100\n",
    "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "  val_roc_score = roc_auc_score(true_bools, pred_bools,average='macro')*100\n",
    "\n",
    "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
    "  print('ROC AUC Score: ', val_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "aiBeiBSRoOuz"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bert_model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFTWxCA_GBau"
   },
   "source": [
    "## Prediction and Metics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "NPvrL6OFSQvf"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# Put model in evaluation mode to evaluate loss on the validation set\n",
    "model.eval()\n",
    "\n",
    "#track variables\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(text_test_loader):\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
    "  with torch.no_grad():\n",
    "    # Forward pass\n",
    "    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    b_logit_pred = outs[0]\n",
    "    pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "    pred_label = pred_label.to('cpu').numpy()\n",
    "    b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "  tokenized_texts.append(b_input_ids)\n",
    "  logit_preds.append(b_logit_pred)\n",
    "  true_labels.append(b_labels)\n",
    "  pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Converting flattened binary values to boolean values\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQeGWqeMzAoZ"
   },
   "source": [
    "We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZcZUcYOxxmM",
    "outputId": "d2b99364-f334-421e-9009-f82c91cf9dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.5038585209003217\n",
      "Test ROC AUC Score:  0.5575571407677811\n",
      "Test Flat Accuracy:  0.05276174773289365 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.46      0.66      0.55       474\n",
      "     Disgust       0.49      0.29      0.36       450\n",
      "        Fear       0.52      0.33      0.40       444\n",
      "       Happy       0.55      0.67      0.60       516\n",
      "         Sad       0.16      0.01      0.03       206\n",
      "    Surprise       0.46      0.25      0.33       412\n",
      "     Neutral       0.70      0.66      0.68       797\n",
      "      Others       0.00      0.00      0.00        75\n",
      "\n",
      "   micro avg       0.55      0.46      0.50      3374\n",
      "   macro avg       0.42      0.36      0.37      3374\n",
      "weighted avg       0.51      0.46      0.47      3374\n",
      " samples avg       0.57      0.49      0.50      3374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test ROC AUC Score: ', roc_auc_score(true_bools, pred_bools,average='macro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n",
    "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rLqrHK87eir"
   },
   "source": [
    "## Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJBkRdGN1hzx",
    "outputId": "857214e2-c4c1-48bf-9517-f664bafcfd1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral', 7: 'Others'}\n"
     ]
    }
   ],
   "source": [
    "idx2label = dict(zip(range(8),label_cols))\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "QZUglV_A4BF_"
   },
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "OOGhXM3R4a91"
   },
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "  if vals:\n",
    "    true_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "  if vals:\n",
    "    pred_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    pred_label_texts.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "5HaqV6pn_HCG"
   },
   "outputs": [],
   "source": [
    "# Decoding input ids to comment text\n",
    "ocr_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "R7kk0Mgl1L-T",
    "outputId": "1d286981-2b54-43af-b02b-9512f0113ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[ ' or this what kind of reputation are these ...</td>\n",
       "      <td>[Angry, Disgust, Fear, Neutral]</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[ ' he is not telling all he knows , do you th...</td>\n",
       "      <td>[Angry, Fear, Neutral]</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[ ' you big stupid why do not you watch where ...</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "      <td>[Angry, Fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[ ' fight it out with him it is the gallows if...</td>\n",
       "      <td>[Angry, Disgust, Fear, Surprise, Neutral]</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[ ' this way to the roof . ' , ' the fleeing b...</td>\n",
       "      <td>[Fear, Happy, Neutral]</td>\n",
       "      <td>[Angry, Fear, Surprise, Neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  \\\n",
       "0  [ ' or this what kind of reputation are these ...   \n",
       "1  [ ' he is not telling all he knows , do you th...   \n",
       "2  [ ' you big stupid why do not you watch where ...   \n",
       "3  [ ' fight it out with him it is the gallows if...   \n",
       "4  [ ' this way to the roof . ' , ' the fleeing b...   \n",
       "\n",
       "                                 true_labels                       pred_labels  \n",
       "0            [Angry, Disgust, Fear, Neutral]                  [Angry, Neutral]  \n",
       "1                     [Angry, Fear, Neutral]                         [Neutral]  \n",
       "2                           [Angry, Neutral]                     [Angry, Fear]  \n",
       "3  [Angry, Disgust, Fear, Surprise, Neutral]                  [Angry, Neutral]  \n",
       "4                     [Fear, Happy, Neutral]  [Angry, Fear, Surprise, Neutral]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'text_clean': ocr_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWFd18u3zlF8"
   },
   "source": [
    "## Bonus - Optimizing threshold value for macro ROC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6mDy1lw0S4y"
   },
   "source": [
    "Doing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHlhb2lvar8V",
    "outputId": "d43381d9-db15-4415-89bb-f5a527911097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold:  0.62\n",
      "Test roc_auc Accuracy:  0.5593396045820264\n",
      "Test Flat Accuracy:  0.05358615004122012 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.50      0.58      0.53       474\n",
      "     Disgust       0.57      0.16      0.24       450\n",
      "        Fear       0.59      0.25      0.36       444\n",
      "       Happy       0.57      0.59      0.58       516\n",
      "         Sad       0.50      0.01      0.02       206\n",
      "    Surprise       0.48      0.14      0.22       412\n",
      "     Neutral       0.74      0.55      0.63       797\n",
      "      Others       0.00      0.00      0.00        75\n",
      "\n",
      "   micro avg       0.59      0.37      0.46      3374\n",
      "   macro avg       0.49      0.29      0.32      3374\n",
      "weighted avg       0.57      0.37      0.42      3374\n",
      " samples avg       0.62      0.40      0.45      3374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy - maximize roc_auc score by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n",
    "\n",
    "macro_thresholds = np.array(range(1,10))/10\n",
    "\n",
    "roc_auc_results, flat_acc_results = [], []\n",
    "for th in macro_thresholds:\n",
    "  pred_bools = [pl>th for pl in pred_labels]\n",
    "  test_roc_auc_accuracy = roc_auc_score(true_bools,pred_bools,average='macro')\n",
    "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "  roc_auc_results.append(test_roc_auc_accuracy)\n",
    "  flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_macro_th = macro_thresholds[np.argmax(roc_auc_results)] #best macro threshold value\n",
    "\n",
    "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
    "\n",
    "roc_auc_results, flat_acc_results = [], []\n",
    "for th in micro_thresholds:\n",
    "  pred_bools = [pl>th for pl in pred_labels]\n",
    "  test_roc_auc_accuracy = roc_auc_score(true_bools,pred_bools,average='macro')\n",
    "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "  roc_auc_results.append(test_roc_auc_accuracy)\n",
    "  flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_roc_auc_idx = np.argmax(roc_auc_results) #best threshold value\n",
    "\n",
    "# Printing and saving classification report\n",
    "print('Best Threshold: ', micro_thresholds[best_roc_auc_idx])\n",
    "print('Test roc_auc Accuracy: ', roc_auc_results[best_roc_auc_idx])\n",
    "print('Test Flat Accuracy: ', flat_acc_results[best_roc_auc_idx], '\\n')\n",
    "\n",
    "best_pred_bools = [pl>micro_thresholds[best_roc_auc_idx] for pl in pred_labels]\n",
    "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
    "pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n",
    "print(clf_report_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred_label_idxs = []\n",
    "for vals in best_pred_bools:\n",
    "    best_pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred_label_texts = []\n",
    "for vals in best_pred_label_idxs:\n",
    "  if vals:\n",
    "    best_pred_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    best_pred_label_texts.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_bert_text_cls'] = best_pred_label_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['image_id','pred_bert_text_cls']].to_csv('../data/public_train/predictions/bert_text_cls_56.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBg6UCYAYtIe",
    "outputId": "16931d0a-f6b3-46c6-f0fc-f01f02826913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5593396045820264"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(true_bools, best_pred_bools,average='macro')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "emotion_text_transformers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
